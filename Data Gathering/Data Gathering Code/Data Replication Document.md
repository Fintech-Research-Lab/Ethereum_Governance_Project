This document replicates the Ethereum project data creation document. This data is designed to empirically test how Ethereum makes decision about finalizing Ethereum Improvement Proposals (EIPs). This project will collect data on EIPs, their status and their authors. This will be supplemented by information about the authors like their twitter and github following, their current and past work history, job titles, and their author's cross-collaboration. We will also identify whether authors belong to Ethereum Client or not. In addition to author information, we will also look at the information about the content of EIPs, we will look at the sentiments on different EIPs by Ethereum community on Magician and we will catagorize discussion topics of Ethereum's development calls where these EIPs are discussed. 
# Data Collection Process
## Creation of Unique Author Ids
The data collection process begins with scraping of data from the website ethereum.org. This website contains information of all EIPs, their status and their authors. This data is collected using a web-scrapping code as of **06/15/2023**. The code is called *???????*. At that point there were 639 EIPs. The output of this file is contained in the file called "allEIPs.csv." In parallel, we manually collected twitter following and author's company and jobs data and created another web scraping code to collect github following data. This code is called *???????*. This process created multiple "formats" of author names. We needed to ensure that author names are uniquely identified. Therefore, to create unique author_ids for each of the authors, we first split authors into author1 to author11, assigned author_ids to the authors as a sequence in the order of EIP numbers, and then used name matching algorithms to match names in twitter, linkedIn, and github data author names. This code is in the file *"Author Name Matching.R"* The name matching process produced a list of all authors of EIPs with a unique author_id. This file is stored in *unique_author_names_with_id.csv"*  
## Manual Reconciliation
The unique author_ids was then matched with twitter, linkedIn, and github following data. However, not all of these names were matched using fuzzy logic algorithm in the Author Name Matching.R code. Therefore, these names were then manually reconciled. There was also a process of incorporating allEIPs.csv file to assign a unique author_id. This process was also manually reconciled to ensure that no author exists that does not have a unique author_id in all datasets, the allEIPs, twitter, linkedIn, and github followings. The final outcome of this exercise was that it created four separate csv files that contains the raw data. First is *ALLEIPS_with_author_id_postmanualreconciliation.csv* This file contains all EIPs that existed as of 6/21/2023 with a unique author_id. The second file is *GitHub_Follower_Data_afterreconciliation.csv* , the third file contains linkedIn data called *LinkedIn_data.csv* Please note that twitter and LinkedIn data were created from a manual data gathering process by our Research Assistant so there is no code. Github and allEIPs data was scrapped from ethereum.org and github respectively 
