This document replicates the Ethereum project data creation document. This data is designed to empirically test how Ethereum makes decision about finalizing Ethereum Improvement Proposals (EIPs). This project will collect data on EIPs, their status and their authors. This will be supplemented by information about the authors like their twitter and github following, their current and past work history, job titles, and their author's cross-collaboration. We will also identify whether authors belong to Ethereum Client or not. In addition to author information, we will also look at the information about the content of EIPs, we will look at the sentiments on different EIPs by Ethereum community on Magician and we will catagorize discussion topics of Ethereum's development calls where these EIPs are discussed. 
# Data Collection Process
The data collection process begins with scraping of data from the website ethereum.org. This website contains information of all EIPs, their status and their authors. This data is collected using a web-scrapping code as of **06/15/2023**. The code is called *???????*. At that point there were 639 EIPs. The output of this file is contained in the file called "allEIPs.csv." This data contains 
## Manual Reconciliation
The unique author_ids was then matched with twitter, linkedIn, and github following data. However, not all of these names were matched using fuzzy logic algorithm in the Author Name Matching.R code. Therefore, these names were then manually reconciled. There was also a process of incorporating allEIPs.csv file to assign a unique author_id. This process was also manually reconciled to ensure that no author exists that does not have a unique author_id in all datasets, the allEIPs, twitter, linkedIn, and github followings. The final outcome of this exercise was that it created four separate csv files that contains the raw data. First is *ALLEIPS_with_author_id_postmanualreconciliation.csv* This file contains all EIPs that existed as of 6/15/2023 with a unique author_id. The second file is *GitHub_Follower_Data_afterreconciliation.csv* , the third file contains linkedIn data called *LinkedIn_data.csv*. The last file is called *twitter_data.csv* which contains the manually obtained twitter data. Please note that twitter and LinkedIn data were created from a manual data gathering process by our Research Assistant so there is no code. Github and allEIPs data was scrapped from ethereum.org and github respectively. 
## Creating Cross-Sectional Ethereum Data by Merging 
Once the raw data exists, we use a stata code called *data merging code.do* to create two files. One contains the cross-sectional data on 639 EIPs and the other contains timeseries data from github commits. The cross-sectional data is generated by first importing *ALLEIPS_with_auther_id_postmanualreconciliation.csv*. This file is converted into a stata file. Then twitter, github, and LinkedIn data is merged to this stata file based on unique author_ids. This create the cross-sectional ethereum data based on EIPs. 
## Generating Commit Data
Apart from the cross-sectional data which is organized by *Ethereum_Data.dta* we have also gathered time series data of github commitments by EIP authors and other contributors. In addition to getting EIP authors, we also flagged author_ids that belong to **Clients** Clients are considered a separate group of contributors that maintain Ethereum codes using different programming languages and maintain that code. One area of possible research is to find out their influence in EIP finalization. Creation of ethereum commit data is through the code file *commit data creation code.do*. As a first step in achieving we updated our *unique_author_names_with_id.csv* file to include one more column that indicated whether the author is part of a client group. We obtained this information from the client repository on the github and matching our github username to the names on the client repository. This updated file is called *unique_author_names_with_id_plusclient* The process of creating commit data is shown in the stata code called *commit data.do* which begins by importing a file called *updated_commit.xlsx* This file is created by scraping commitments on Ethereum EIPs useing *????????* code. This file contains all commits made to EIPs along with unique author_id of who made these commitments. It also contain authors that are not in our author database, we call them *"eip_contributors"* because they commit to EIPs but they are not EIP authors. This file is a time series file so it also contains dates of commitments. It is a panel data which is organized by EIPs and date. We save this file as a stata file. We also import *unique_author_names_with_id_plusclient* and save it as a stata file. Then, we merge commit data with author data by bringing information about whether the author is a client or not. We then flag a dummy variable. We also create a flag of whether the contributor is an EIP author or not and flag it as a dummy variable as well. Final step is to merge the timeseries of commit data with cross-sectional *ethereum_commit.dta* to bring all cross-sectional elements in one panel data file which we call *Ethereum Panel Data.dta*
