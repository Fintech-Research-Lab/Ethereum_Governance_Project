This document replicates the Ethereum project data creation document. This data is designed to empirically test how Ethereum makes decision about finalizing Ethereum Improvement Proposals (EIPs). This project will collect data on EIPs, their status and their authors. This will be supplemented by information about the authors like their twitter and github following, their current and past work history, job titles, and their author's cross-collaboration. We will also identify whether authors belong to Ethereum Client or not. In addition to author information, we will also look at the information about the content of EIPs, we will look at the sentiments on different EIPs by Ethereum community on Magician and we will catagorize discussion topics of Ethereum's development calls where these EIPs are discussed. 
# Data Collection Process
The data collection process begins with scraping of data from the website ethereum.org. This website contains information of all EIPs, their status and their authors. This data is collected using a web-scrapping code as of **06/15/2023**. The following steps were taken:
* Use code *?????????* to create a file which contains 639 EIPs. This file contains EIP Number, Authors, Status, and Title.
* Modify data to split Authors in upto 11 authors if EIPs are co-authored and provided a unique author_id. The result is the file called *AllEIPs.csv* 
## Manual Collection
We manually collect the following data
* Twitter Data: We manually collected information on the authors' Twitter following and Twitter followers, if available. This data is in *Twitter_Data.csv*.
* GitHub Data : We collect author's github following, if available. This data is *Github_Data.csv*.
* LinkedIn Data: We also manually collected data from LinkedIn, capturing details of up to four current companies where the authors are presently employed, along with their job titles. Additionally, we gathered information on up to the last 10 companies where they had previously worked, including their past job titles. This is in *LinkedIn_Data.csv*
* Past Job Titles: For the most recent four companies where the authors worked, we collected the past job titles as follows:
  - For the most recent past company, we obtained three previous job titles.
  - For the two companies before the most recent past company, we collected two previous job titles for each.
  - Lastly, for the fourth oldest company where the author worked, we recorded one previous job title.
## Creating Cross-Sectional Ethereum Data by Merging 
We use a stata code called *data merging code.do* to create the cross-sectional data organized by EIP_Number. The following steps describe the process:
* The cross-sectional data is generated by first importing *AllEIPs.csv*. This file is converted into a stata file.
* Twitter, github, and LinkedIn data is merged to this stata file based on unique author_ids. This create the cross-sectional ethereum data based on EIPs. This data is stored in *Ethereum_Crosssectional_Data.dta*. 
## Generating Commit Data
Apart from the cross-sectional data which is organized by *EIP_Number* we have also gathered time series data of github commitments by **Clients** and **EIP_Authors**. The steps involve gathering all commit data from github. As a first step, we gather information from the github *EIP Respoistory* then we collect data from github's client repositories.  The following steps were taken to collect this data:
* Use code *?????????* to web scrape data from github's EIP repository to find commits by date, author (github username), commit hash code, and commit title. This data is available in file called *updated_commit.xlsx*.
* Matched this commit data to a list of author_ids that contains github_usernames so that we can identify whether the commit contributor was an EIP Author and was a Client who also happens to be an EIP author. This code is produced in *commit data creation code.do*.
  - First import the file *updated_commit.xlsx*  This file is a time series file as it contains dates of commitments. We store it as a stata file *ethereum_commit.dta*.It is a panel data which is organized by EIPs and date.
  - Then, we merge commit data with the list of author data with id in file . We then flag a dummy variable. We also create a flag of whether the contributor is an EIP author or not and flag it as a dummy variable as well. Final step is to merge the timeseries of commit data with cross-sectional *ethereum_commit.dta* to bring all cross-sectional elements in one panel data file which we call *Ethereum Panel Data.dta*
